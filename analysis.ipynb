{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TikTok Ad Research with Commercial Content API\n\n",
        "This notebook guides you through researching TikTok ads using the Commercial Content API, as described in the Medium post [How to Research TikTok Ads with the Commercial Content API](https://medium.com/@poorolive51/how-to-research-tiktok-ads-with-the-commercial-content-api-e9059edd0cbe)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n\n",
        "First, let's install the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, you'll need to add your TikTok API credentials to a `.env` file. You can copy the `.env.example` file to `.env` and fill in your `TIKTOK_CLIENT_KEY` and `TIKTOK_CLIENT_SECRET`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authentication\n\n",
        "Before making any API calls, you need to obtain an access token. This token is valid for 2 hours and needs to be regenerated for each query session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n\n",
        "load_dotenv()\n\n",
        "def fetch_access_token():\n",
        "    \"\"\"Authenticate and return a TikTok API access token.\"\"\"\n",
        "    client_key = os.getenv(\"TIKTOK_CLIENT_KEY\")\n",
        "    client_secret = os.getenv(\"TIKTOK_CLIENT_SECRET\")\n\n",
        "    if not client_key or not client_secret:\n",
        "        raise ValueError(\"Please set TIKTOK_CLIENT_KEY and TIKTOK_CLIENT_SECRET in your .env file.\")\n\n",
        "    token_url = \"https://open.tiktokapis.com/v2/oauth/token/\"\n",
        "    token_data = {\n",
        "        \"client_key\": client_key,\n",
        "        \"client_secret\": client_secret,\n",
        "        \"grant_type\": \"client_credentials\"\n",
        "    }\n\n",
        "    response = requests.post(token_url, data=token_data)\n",
        "    response.raise_for_status()\n",
        "    token_json = response.json()\n\n",
        "    if \"access_token\" not in token_json:\n",
        "        raise RuntimeError(f\"Failed to retrieve access token: {token_json}\")\n\n",
        "    print(f\"Access token obtained. Expires in: {token_json.get('expires_in', 'N/A')} seconds.\")\n",
        "    return token_json[\"access_token\"]\n\n",
        "access_token = fetch_access_token()\n",
        "# Optionally save to .env for other scripts to use, though notebook will pass it directly\n",
        "# with open(\".env\", \"a\") as f:\n",
        "#     f.write(f\"TIKTOK_ACCESS_TOKEN={access_token}\\n\")\n",
        "print(\"Authentication complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Collect Ad IDs by Keyword\n\n",
        "This step collects TikTok Ad Library ad IDs for specified keywords, country, and time range. Due to API limitations (e.g., max 10 ads per query), the script iterates over 10-day chunks to capture more ads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from dateutil.relativedelta import relativedelta\n\n",
        "# CONFIGURATION\n",
        "COUNTRY = \"NL\"  # Two-letter ISO country code\n",
        "MONTHS_BACK = 12  # How far back to search from today\n",
        "MAX_ADS_PER_REQUEST = 20  # TikTok API max per request\n",
        "DATE_INCREMENT_DAYS = 10  # Chunk size for date ranges\n",
        "MAX_PAGES = 1000  # Safety limit for pagination\n",
        "MAX_TOTAL_ADS = 10000  # Max ads collected per keyword\n",
        "FIXED_RATE_LIMIT_DELAY = 1  # Delay between requests (seconds)\n\n",
        "AD_QUERY_URL = \"https://open.tiktokapis.com/v2/research/adlib/ad/query/\"\n",
        "base_headers = {\n",
        "    \"authorization\": f\"bearer {access_token}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "query_fields = \"ad.id,ad.first_shown_date,ad.last_shown_date,advertiser.business_name\"\n\n",
        "def collect_ad_ids(search_term):\n",
        "    \"\"\"Collect unique ad IDs for a given keyword over the past MONTHS_BACK months.\"\"\"\n",
        "    today = datetime.now()\n",
        "    max_date_dt = today - timedelta(days=1)\n",
        "    start_date_dt = max_date_dt - relativedelta(months=MONTHS_BACK)\n",
        "    \n",
        "    all_ads = []\n",
        "    seen_ids = set()\n",
        "    current_date = start_date_dt\n\n",
        "    while current_date < max_date_dt:\n",
        "        chunk_start = current_date.strftime(\"%Y%m%d\")\n",
        "        chunk_end_dt = min(current_date + timedelta(days=DATE_INCREMENT_DAYS - 1), max_date_dt)\n",
        "        chunk_end = chunk_end_dt.strftime(\"%Y%m%d\")\n",
        "        \n",
        "        print(f\"\\nSearching ads from {chunk_start} to {chunk_end} for '{search_term}'\")\n",
        "        \n",
        "        offset = 0\n",
        "        page_count = 0\n",
        "        has_more = True\n",
        "        \n",
        "        while has_more and page_count < MAX_PAGES and len(all_ads) < MAX_TOTAL_ADS:\n",
        "            page_count += 1\n",
        "            request_body = {\n",
        "                \"filters\": {\n",
        "                    \"ad_published_date_range\": {\n",
        "                        \"min\": chunk_start,\n",
        "                        \"max\": chunk_end\n",
        "                    },\n",
        "                    \"country\": COUNTRY\n",
        "                },\n",
        "                \"search_term\": search_term,\n",
        "                \"search_type\": \"fuzzy_phrase\",\n",
        "                \"max_count\": MAX_ADS_PER_REQUEST,\n",
        "                \"offset\": offset\n",
        "            }\n",
        "            \n",
        "            try:\n",
        "                resp = requests.post(\n",
        "                    AD_QUERY_URL,\n",
        "                    headers=base_headers,\n",
        "                    params={"fields": query_fields},\n",
        "                    json=request_body\n",
        "                )\n",
        "                \n",
        "                if resp.status_code == 429:  # Rate-limited: wait and retry\n",
        "                    print(\"Rate limited. Waiting 5s...\")\n",
        "                    time.sleep(5)\n",
        "                    continue\n",
        "                \n",
        "                resp.raise_for_status()\n",
        "                data = resp.json().get(\"data\", { })\n",
        "                ads = data.get(\"ads\", [])\n",
        "                \n",
        "                for ad in ads:\n",
        "                    ad_id = ad.get(\"ad\", {}).get(\"id\")\n",
        "                    if ad_id and ad_id not in seen_ids:\n",
        "                        seen_ids.add(ad_id)\n",
        "                        all_ads.append({\n",
        "                            \"id\": ad_id,\n",
        "                            \"basic_info\": ad\n",
        "                        })\n",
        "                \n",
        "                offset = data.get(\"offset\", offset + MAX_ADS_PER_REQUEST)\n",
        "                has_more = data.get(\"has_more\", False)\n",
        "                \n",
        "                if has_more:\n",
        "                    time.sleep(FIXED_RATE_LIMIT_DELAY)\n",
        "            except requests.RequestException as e:\n",
        "                print(f\"Request error: {e}\")\n",
        "                break\n",
        "        \n",
        "        current_date += timedelta(days=DATE_INCREMENT_DAYS)\n\n",
        "    # Save to file\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    min_date = start_date_dt.strftime(\"%Y%m%d\")\n",
        "    max_date = max_date_dt.strftime(\"%Y%m%d\")\n",
        "    keyword_safe = ".".join(c if c.isalnum() else "_" for c in search_term)\n",
        "    filename = f\"tiktok_ad_ids_{COUNTRY}_{keyword_safe}_{min_date}_to_{max_date}_{timestamp}.json\"\n",
        "    \n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_ads, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"Saved {len(all_ads)} ads to {filename}\")\n",
        "    return filename\n\n",
        "# Example Usage (uncomment and modify to run):\n",
        "# search_term = \"your_keyword\"\n",
        "# ad_ids_file = collect_ad_ids(search_term)\n",
        "# print(f\"Collected ad IDs saved to: {ad_ids_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Get Ad Details\n\n",
        "Once you have a list of ad IDs, you can fetch their detailed metadata using the ad details endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_ad_details(access_token, ad_id):\n",
        "    \"\"\"Retrieve detailed metadata for a single TikTok ad.\"\"\"\n",
        "    ad_detail_url = (\n",
        "        \"https://open.tiktokapis.com/v2/research/adlib/ad/detail/\"\n",
        "        \"?fields=ad.id,ad.first_shown_date,ad.last_shown_date,\"\n",
        "        \"ad.image_urls,ad.videos,ad.reach,ad.rejection_info,\"\n",
        "        \"ad_group.targeting_info,advertiser.business_id,\"\n",
        "        \"advertiser.business_name,advertiser.paid_for_by,advertiser.profile_url\"\n",
        "    )\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {access_token}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\"ad_id\": ad_id}\n\n",
        "    try:\n",
        "        resp = requests.post(ad_detail_url, headers=headers, json=payload)\n",
        "        resp.raise_for_status()\n",
        "        return resp.json()\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching ad {ad_id}: {e}\")\n",
        "        return {\"ad_id\": ad_id, \"error\": str(e)}\n\n",
        "# Example Usage (uncomment and modify to run):\n",
        "# if 'ad_ids_file' in locals():\n",
        "#     with open(ad_ids_file, \"r\", encoding=\"utf-8\") as f:\n",
        "#         ads_data = json.load(f)\n",
        "#     ad_ids = [ad[\"id\"] for ad in ads_data if \"id\" in ad]\n",
        "#     \n",
        "#     all_details = []\n",
        "#     for idx, ad_id in enumerate(ad_ids, start=1):\n",
        "#         print(f\"[{idx}/{len(ad_ids)}] Fetching details for ad {ad_id}...\")\n",
        "#         details = fetch_ad_details(access_token, ad_id)\n",
        "#         all_details.append(details)\n",
        "#         time.sleep(0.5) # Be kind to the API\n",
        "#     \n",
        "#     output_details_file = ad_ids_file.replace(\"tiktok_ad_ids\", \"tiktok_detailed_ads\")\n",
        "#     with open(output_details_file, \"w\", encoding=\"utf-8\") as f:\n",
        "#         json.dump(all_details, f, indent=2, ensure_ascii=False)\n",
        "#     print(f\"âœ… Done! Detailed ad data saved to {output_details_file}\")\n",
        "# else:\n",
        "#     print(\"Please run the 'Collect Ad IDs' section first to get ad_ids_file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analysis and Plotting: Top Advertisers\n\n",
        "This section processes the detailed ad data and generates an interactive Plotly graph showing the top N advertisers' ad reach over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_reach_value(reach_str):\n",
        "    \"\"\" Converts a reach string like '10K-100K' or '94K' to a numeric value. Ranges are converted to their midpoint. \"\"\"\n",
        "    if not reach_str: return 0\n",
        "    reach_str = reach_str.upper().replace(',', '')\n",
        "    if '-' in reach_str:\n",
        "        parts = reach_str.split('-')\n",
        "        min_val = parse_single_reach(parts[0])\n",
        "        max_val = parse_single_reach(parts[1])\n",
        "        return (min_val + max_val) / 2\n",
        "    else:\n",
        "        return parse_single_reach(reach_str)\n\n",
        "def parse_single_reach(value_str):\n",
        "    \"\"\"Parses a single reach value string, e.g., '10K' or '1M'.\"\"\"\n",
        "    if 'K' in value_str: return float(value_str.replace('K', '')) * 1000\n",
        "    elif 'M' in value_str: return float(value_str.replace('M', '')) * 1000000\n",
        "    else: return float(value_str)\n\n",
        "def parse_date(date_str):\n",
        "    \"\"\"Converts a date string like '20240808' to a datetime object.\"\"\"\n",
        "    return datetime.strptime(date_str, '%Y%m%d')\n\n",
        "def load_and_process_ad_data(json_file_path):\n",
        "    \"\"\" Loads ad data from a JSON file and processes it into a list of dictionaries. \"\"\"\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    ads_data = []\n",
        "    if isinstance(data, dict): data = [data]\n",
        "    for item in data:\n",
        "        try:\n",
        "            if 'data' in item:\n",
        "                ad_info = item['data']['ad']\n",
        "                advertiser_info = item['data'].get('advertiser', { })\n",
        "            else:\n",
        "                ad_info = item.get('ad', item)\n",
        "                advertiser_info = item.get('advertiser', { })\n",
        "            if 'error' in item and item['error']['code'] != 'ok':\n",
        "                continue\n",
        "            if 'id' not in ad_info or 'first_shown_date' not in ad_info:\n",
        "                continue\n",
        "            ad_id = ad_info['id']\n",
        "            first_shown = parse_date(ad_info['first_shown_date'])\n",
        "            last_shown = parse_date(ad_info['last_shown_date'])\n",
        "            reach_info = ad_info.get('reach', { })\n",
        "            global_reach = parse_reach_value(reach_info.get('unique_users_seen', '0'))\n",
        "            country_reach = reach_info.get('unique_users_seen_by_country', { })\n",
        "            total_country_reach = sum(parse_reach_value(v) for v in country_reach.values())\n",
        "            reach_volume = max(global_reach, total_country_reach)\n",
        "            advertiser_name = advertiser_info.get('business_name', 'Unknown')\n",
        "            ads_data.append({\n",
        "                'ad_id': ad_id,\n",
        "                'first_shown': first_shown,\n",
        "                'last_shown': last_shown,\n",
        "                'reach_volume': reach_volume,\n",
        "                'advertiser': advertiser_name\n",
        "            })\n",
        "        except (KeyError, ValueError) as e:\n",
        "            continue\n",
        "    return ads_data\n\n",
        "def create_date_range_data(ads_data):\n",
        "    \"\"\" Expands ad data into daily records for a given date range. \"\"\"\n",
        "    daily_data = []\n",
        "    for ad in ads_data:\n",
        "        current_date = ad['first_shown']\n",
        "        while current_date <= ad['last_shown']:\n",
        "            daily_data.append({\n",
        "                'date': current_date,\n",
        "                'ad_id': ad['ad_id'],\n",
        "                'reach_volume': ad['reach_volume'],\n",
        "                'advertiser': ad['advertiser']\n",
        "            })\n",
        "            current_date += timedelta(days=1)\n",
        "    return pd.DataFrame(daily_data)\n\n",
        "def plot_top_advertisers_plotly(df, top_n=5):\n",
        "    \"\"\"Generates an interactive Plotly plot for the top N advertisers over time.\"\"\"\n",
        "    advertiser_totals = df.groupby('advertiser')['reach_volume'].sum().sort_values(ascending=False)\n",
        "    top_advertisers = advertiser_totals.head(top_n).index.tolist()\n",
        "    \n",
        "    df_top = df[df['advertiser'].isin(top_advertisers)].copy()\n",
        "    advertiser_daily = df_top.groupby(['date', 'advertiser'])['reach_volume'].sum().reset_index()\n\n",
        "    fig = go.Figure()\n",
        "    for advertiser in top_advertisers:\n",
        "        advertiser_data = advertiser_daily[advertiser_daily['advertiser'] == advertiser].sort_values('date')\n",
        "        if not advertiser_data.empty:\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=advertiser_data['date'],\n",
        "                y=advertiser_data['reach_volume'],\n",
        "                mode='lines+markers',\n",
        "                name=advertiser,\n",
        "                hovertemplate='<b>Advertiser:</b> %{fullData.name}<br>' + \n",
        "                                '<b>Date:</b> %{x|%Y-%m-%d}<br>' + \n",
        "                                '<b>Daily Volume:</b> %{y:,.0f}<br>' + \n",
        "                                '<extra></extra>',\n",
        "                connectgaps=False\n",
        "            ))\n\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': f'Top {top_n} Advertisers: Ad Reach Over Time',\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center'\n",
        "        },\n",
        "        xaxis_title='Date',\n",
        "        yaxis_title='Daily Reach (Users)',\n",
        "        plot_bgcolor='white',\n",
        "        paper_bgcolor='white',\n",
        "        hovermode='x unified',\n",
        "        legend=dict(\n",
        "            orientation=\"v\",\n",
        "            yanchor=\"top\",\n",
        "            y=1,\n",
        "            xanchor=\"left\",\n",
        "            x=0.02\n",
        "        )\n",
        "    )\n\n",
        "    fig.update_xaxes(\n",
        "        showgrid=True,\n",
        "        gridwidth=1,\n",
        "        gridcolor='rgba(128, 128, 128, 0.2)',\n",
        "        showline=True,\n",
        "        linewidth=1,\n",
        "        linecolor='rgb(204, 204, 204)'\n",
        "    )\n\n",
        "    fig.update_yaxes(\n",
        "        showgrid=True,\n",
        "        gridwidth=1,\n",
        "        gridcolor='rgba(128, 128, 128, 0.2)',\n",
        "        showline=True,\n",
        "        linewidth=1,\n",
        "        linecolor='rgb(204, 204, 204)',\n",
        "        tickformat='.0s'\n",
        "    )\n\n",
        "    return fig\n\n",
        "# Example Usage (uncomment and modify to run):\n",
        "# if 'output_details_file' in locals():\n",
        "#     try:\n",
        "#         ads_data_processed = load_and_process_ad_data(output_details_file)\n",
        "#         if ads_data_processed:\n",
        "#             df_daily_top_advertisers = create_date_range_data(ads_data_processed)\n",
        "#             fig_top_advertisers = plot_top_advertisers_plotly(df_daily_top_advertisers, top_n=5)\n",
        "#             fig_top_advertisers.show()\n",
        "#         else:\n",
        "#             print(\"No ad data was processed for top advertisers. Please check your JSON file.\")\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"Error: {output_details_file} not found. Please ensure the file path is correct.\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"An unexpected error occurred during top advertisers plotting: {e}\")\n",
        "# else:\n",
        "#     print(\"Please run the 'Get Ad Details' section first to get output_details_file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analysis and Plotting: Total Ad Volume\n\n",
        "This section processes the detailed ad data and generates an interactive Plotly graph showing the total ad reach volume over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_total_volume_plot(df):\n",
        "    \"\"\" Generates an interactive Plotly plot of total ad volume over time. \"\"\"\n",
        "    daily_totals = df.groupby('date')['reach_volume'].sum().reset_index()\n\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=daily_totals['date'],\n",
        "        y=daily_totals['reach_volume'],\n",
        "        mode='lines+markers',\n",
        "        name='Total Ad Volume',\n",
        "        hovertemplate='<b>Date:</b> %{x|%Y-%m-%d}<br>' + \n",
        "                        '<b>Total Volume:</b> %{y:,.0f}<br>' + \n",
        "                        '<extra></extra>'
",
        "    ))\n\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': 'Total Ad Reach Over Time',\n",
        "            'x': 0.5,\n",
        "            'xanchor': 'center'\n",
        "        },\n",
        "        yaxis_title='Total Reach (Users)',\n",
        "        plot_bgcolor='white',\n",
        "        paper_bgcolor='white',\n",
        "        hovermode='x unified',\n",
        "        showlegend=False\n",
        "    )\n\n",
        "    fig.update_xaxes(\n",
        "        showgrid=True,\n",
        "        gridwidth=1,\n",
        "        gridcolor='rgba(128, 128, 128, 0.2)',\n",
        "        showline=True,\n",
        "        linewidth=1,\n",
        "        linecolor='rgb(204, 204, 204)'\n",
        "    )\n\n",
        "    fig.update_yaxes(\n",
        "        showgrid=True,\n",
        "        gridwidth=1,\n",
        "        gridcolor='rgba(128, 128, 128, 0.2)',\n",
        "        showline=True,\n",
        "        linewidth=1,\n",
        "        linecolor='rgb(204, 204, 204)',\n",
        "        tickformat='.0s'\n",
        "    )\n\n",
        "    return fig\n\n",
        "# Example Usage (uncomment and modify to run):\n",
        "# if 'output_details_file' in locals():\n",
        "#     try:\n",
        "#         ads_data_processed = load_and_process_ad_data(output_details_file)\n",
        "#         if ads_data_processed:\n",
        "#             df_daily_total_volume = create_date_range_data(ads_data_processed)\n",
        "#             fig_total_volume = create_total_volume_plot(df_daily_total_volume)\n",
        "#             fig_total_volume.show()\n",
        "#         else:\n",
        "#             print(\"No ad data was processed for total volume. Please check your JSON file.\")\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"Error: {output_details_file} not found. Please ensure the file path is correct.\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"An unexpected error occurred during total volume plotting: {e}\")\n",
        "# else:\n",
        "#     print(\"Please run the 'Get Ad Details' section first to get output_details_file.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}